# MSc in AI Demokritos Multiagent Systems Course Assignment
## Equilibria computation in zero-sum games

In the current assignment we examine two methods for the computation of equilibria in zero sum games. We demonstrate their theoretical foundations and 
we test them on several games. We illustrate their behaviour regarding their convergence and we compare them to each other. 

The first one is the **Fictitious Play**, 
a prominent **model-based** learning rule (implementation in [fictitious_play.py]) and 
the second one is **Reinforcement Learning**, in a **model-free approach** (implementation in [minmax_Q_RL.py]). 

The structure and content of this assignment is mostly inspired from the 
book Multiagent Systems: *Algorithmic, Game-Theoretic, and Logical Foundations* of Yoav Shoham and Kevin Leyton-Brown.

The report is found in [Report.pdf].

[//]: # (These are reference links used in the body of this note and get stripped out when the markdown processor does its job. There is no need to format nicely because it shouldn't be seen. Thanks SO - http://stackoverflow.com/questions/4823468/store-comments-in-markdown-syntax)

[Report.pdf]:
<https://github.com/tatiana-boura/MSc-in-AI-Demokritos-Multiagent-Systems-Course/blob/master/REPORT.pdf>
[fictitious_play.py]:
<https://github.com/tatiana-boura/MSc-in-AI-Demokritos-Multiagent-Systems-Course/blob/master/fictitious_play.py>
[minmax_Q_RL.py]:
<https://github.com/tatiana-boura/MSc-in-AI-Demokritos-Multiagent-Systems-Course/blob/master/minmax_Q_RL.py>
